{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "902a8151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a389e95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 11:56:04.239271: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-18 11:56:04.240340: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n"
     ]
    }
   ],
   "source": [
    "mnist_dataset, mnist_info= tfds.load(name='mnist', with_info= True, as_supervised=True)\n",
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']\n",
    "\n",
    "num_validation_samples = 0.1*mnist_info.splits['train'].num_examples\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n",
    "num_test_samples = mnist_info.splits ['test'].num_examples\n",
    "\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)\n",
    "\n",
    "def scale (image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255.\n",
    "    return image, label\n",
    "scaled_train_and_validation_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ccd6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 11:56:04.445782: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-01-18 11:56:05.844307: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "Buffer_size = 10000\n",
    "\n",
    "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(Buffer_size)\n",
    "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n",
    "train_data = shuffled_train_and_validation_data.skip(num_validation_samples)\n",
    "\n",
    "Batch_size = 100\n",
    "\n",
    "train_data = train_data.batch(Batch_size)\n",
    "validation_data = validation_data.batch(num_validation_samples)\n",
    "test_data = test_data.batch(num_test_samples)\n",
    "validation_inputs, validation_targets = next(iter(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d3833b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation= 'relu', input_shape = (28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation= 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation= 'relu')\n",
    "    \n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17491644",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation = 'relu'))\n",
    "model.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90b22f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71746054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 39s - loss: 0.2361 - accuracy: 0.9276 - val_loss: 0.0644 - val_accuracy: 0.9807\n",
      "Epoch 2/5\n",
      "540/540 - 29s - loss: 0.0580 - accuracy: 0.9820 - val_loss: 0.0499 - val_accuracy: 0.9832\n",
      "Epoch 3/5\n",
      "540/540 - 28s - loss: 0.0399 - accuracy: 0.9873 - val_loss: 0.0387 - val_accuracy: 0.9880\n",
      "Epoch 4/5\n",
      "540/540 - 30s - loss: 0.0312 - accuracy: 0.9901 - val_loss: 0.0406 - val_accuracy: 0.9872\n",
      "Epoch 5/5\n",
      "540/540 - 29s - loss: 0.0251 - accuracy: 0.9918 - val_loss: 0.0296 - val_accuracy: 0.9918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8a22623e20>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "model.fit(train_data, epochs = num_epochs, validation_data=(validation_inputs,validation_targets), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e70a8495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0311 - accuracy: 0.9912\n",
      "<built-in method format of str object at 0x7f8a1a1ee2d0>\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_accuracy = model.evaluate(test_data)\n",
    "print('Test loss: {0:.2f}, Test accuracy: {1:.2f}%'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0300d157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-environment",
   "language": "python",
   "name": "tensorflow-environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
